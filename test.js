const axios = require('axios');

// Funci√≥n para probar la conexi√≥n con el servidor
async function testConnection() {
    console.log('üîç Probando conexi√≥n con el servidor...\n');
    
    try {
        // Probar estado del servidor
        const statusResponse = await axios.get('http://localhost:3000/api/status');
        console.log('‚úÖ Estado del servidor:', statusResponse.data);
        
        // Probar modelos disponibles
        try {
            const modelsResponse = await axios.get('http://localhost:3000/api/models');
            console.log('\nüì¶ Modelos disponibles:', modelsResponse.data);
            
            // Si el modelo preferido est√° disponible, hacer una pregunta de prueba
            if (modelsResponse.data.models && modelsResponse.data.models.includes('qwen/qwen3-4b-2507')) {
                console.log('\nüéØ Modelo qwen/qwen3-4b-2507 encontrado! Haciendo pregunta de prueba...');
                await testChat();
            } else {
                console.log('\n‚ö†Ô∏è  Modelo qwen/qwen3-4b-2507 no encontrado en LMStudio');
                console.log('   Aseg√∫rate de cargar este modelo en LMStudio');
            }
            
        } catch (error) {
            console.log('\n‚ùå Error obteniendo modelos:', error.response?.data || error.message);
        }
        
    } catch (error) {
        console.log('‚ùå Error conectando con el servidor:', error.message);
        console.log('   Aseg√∫rate de que el servidor est√© ejecut√°ndose en http://localhost:3000');
    }
}

// Funci√≥n para probar el chat
async function testChat() {
    try {
        const response = await axios.post('http://localhost:3000/api/chat', {
            message: '¬°Hola! ¬øPuedes confirmar que eres el modelo qwen/qwen3-4b-2507?',
            model: 'qwen/qwen3-4b-2507',
            max_tokens: 100,
            temperature: 0.5
        });
        
        console.log('\nü§ñ Respuesta del AI:');
        console.log(response.data.response);
        console.log(`\nüìä Informaci√≥n:
   - Modelo usado: ${response.data.model}
   - Tokens usados: ${response.data.tokens_used}
   - Tiempo: ${response.data.timestamp}`);
        
    } catch (error) {
        console.log('\n‚ùå Error en el chat:', error.response?.data || error.message);
    }
}

// Funci√≥n para hacer una pregunta personalizada
async function askQuestion(question) {
    console.log(`\n‚ùì Pregunta: ${question}\n`);
    
    try {
        console.log('üîÑ Enviando petici√≥n al servidor...');
        const response = await axios.post('http://localhost:3000/api/chat', {
            message: question,
            model: 'qwen/qwen3-4b-2507',
            max_tokens: 300,
            temperature: 0.5
        }, {
            timeout: 60000 // 60 segundos
        });
        
        console.log('ü§ñ Respuesta:');
        console.log(response.data.response);
        console.log(`\nüìä Tokens usados: ${response.data.tokens_used}`);
        
    } catch (error) {
        console.log('‚ùå Error:', error.response?.data?.error || error.message);
        if (error.response) {
            console.log('üìã Detalles completos:', JSON.stringify(error.response.data, null, 2));
        }
    }
}

// Obtener argumentos de l√≠nea de comandos
const args = process.argv.slice(2);

if (args.length === 0) {
    // Sin argumentos, ejecutar prueba de conexi√≥n
    testConnection();
} else if (args[0] === 'ask') {
    // Hacer una pregunta personalizada
    const question = args.slice(1).join(' ');
    if (question) {
        askQuestion(question);
    } else {
        console.log('‚ùå Por favor proporciona una pregunta despu√©s de "ask"');
        console.log('   Ejemplo: node test.js ask "¬øCu√°l es la capital de Francia?"');
    }
} else {
    // Usar todos los argumentos como una pregunta
    const question = args.join(' ');
    askQuestion(question);
}
