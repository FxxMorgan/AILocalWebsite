# ü§ñ Gu√≠a de Modelos para LMStudio

## Modelos Recomendados por Tama√±o (de menor a mayor)

### üü¢ **Modelos Ligeros (2-4GB RAM)**
Perfectos para sistemas con poca memoria:

1. **microsoft/Phi-3-mini-4k-instruct** - 3.8B par√°metros
   - Muy r√°pido y eficiente
   - Excelente para tareas generales
   - Funciona bien en laptops

2. **microsoft/Phi-3.5-mini-instruct** - 3.8B par√°metros
   - Versi√≥n mejorada del Phi-3 mini
   - Mejor comprensi√≥n de contexto

### üü° **Modelos Medianos (4-8GB RAM)**
Buen balance entre rendimiento y recursos:

3. **meta-llama/Llama-3.2-3B-Instruct** - 3B par√°metros
   - Muy buena calidad de respuestas
   - R√°pido en inferencia

4. **microsoft/Phi-3-medium-4k-instruct** - 14B par√°metros
   - Mucho mejor en tareas complejas
   - Requiere m√°s memoria

### üü† **Modelos Grandes (8-16GB RAM)**
Para sistemas con m√°s recursos:

5. **meta-llama/Llama-3.2-7B-Instruct** - 7B par√°metros
   - Excelente calidad
   - Muy bueno para programaci√≥n

6. **meta-llama/Llama-3.1-8B-Instruct** - 8B par√°metros
   - Una de las mejores opciones
   - Muy vers√°til

### üî¥ **Modelos Muy Grandes (16GB+ RAM)**
Solo para sistemas potentes:

7. **openai/gpt-oss-20b** - 20B par√°metros
   - Muy alta calidad
   - Requiere mucha memoria
   - Puede ser lento en sistemas normales

## üõ†Ô∏è **Configuraci√≥n Recomendada por Sistema**

### **Sistema B√°sico (8GB RAM o menos)**
```
Modelo recomendado: Phi-3-mini-4k-instruct
Max tokens: 300-500
Temperature: 0.7
```

### **Sistema Intermedio (8-16GB RAM)**
```
Modelo recomendado: Llama-3.2-3B o Llama-3.2-7B
Max tokens: 500-1000
Temperature: 0.7
```

### **Sistema Potente (16GB+ RAM)**
```
Modelo recomendado: Llama-3.1-8B o superior
Max tokens: 1000-2048
Temperature: 0.7
```

## üì• **C√≥mo Descargar Modelos en LMStudio**

1. Abre LMStudio
2. Ve a la pesta√±a "Search" o "Models"
3. Busca el nombre del modelo (ej: "Phi-3-mini")
4. Haz clic en "Download"
5. Espera a que termine la descarga
6. Ve a la pesta√±a "Developer"
7. Selecciona el modelo descargado
8. Haz clic en "Start Server"

## ‚ö° **Optimizaci√≥n de Rendimiento**

### **Para sistemas lentos:**
- Usa modelos quantizados (Q4, Q5, Q8)
- Reduce max_tokens a 200-300
- Baja la temperatura a 0.5
- Cierra otras aplicaciones

### **Para mejor calidad:**
- Usa modelos m√°s grandes si tienes RAM
- Aumenta max_tokens a 1000+
- Experimenta con temperature entre 0.7-0.9

## üîç **Verificar Recursos del Sistema**

### **Windows:**
- Abre "Administrador de tareas" (Ctrl+Shift+Esc)
- Ve a la pesta√±a "Rendimiento"
- Mira "Memoria" para ver RAM disponible

### **Recomendaci√≥n:**
- Deja al menos 2-4GB de RAM libre para el sistema
- El modelo deber√≠a usar m√°ximo 60-70% de tu RAM total
