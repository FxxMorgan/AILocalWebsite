# Configuración de ejemplo para AI Chat Local
# Copia este archivo como .env y modifica según tus necesidades

# Puerto del servidor
PORT=3000

# URL de LMStudio (normalmente no necesitas cambiar esto)
LMSTUDIO_URL=http://localhost:1234

# Configuración por defecto del modelo
DEFAULT_MODEL=qwen/qwen3-4b-2507
DEFAULT_MAX_TOKENS=500
DEFAULT_TEMPERATURE=0.7

# Configuración de timeouts y reintentos
LM_TIMEOUT_MS=60000
LM_MAX_RETRIES=2

# Modo verbose para debugging (true/false)
VERBOSE_LM=false

# Precalentar modelo al iniciar (true/false)
WARMUP_ON_START=false

# Modelos que requieren formato raw (separados por comas)
# Ejemplos: nsfw-3b,otro-modelo*,modelo-especial
FORCE_RAW_MODELS=

# API Key opcional (para futuras integraciones)
API_KEY=
